"use strict";(self.webpackChunkpush_website=self.webpackChunkpush_website||[]).push([[51265],{89550:(e,a,t)=>{t.r(a),t.d(a,{assets:()=>c,contentTitle:()=>l,default:()=>p,frontMatter:()=>d,metadata:()=>o,toc:()=>h});var n=t(85893),s=t(11151),i=t(74866),r=t(85162);const d={id:"docs-video-quickstart",title:"Quickstart",hide_title:!1,slug:"./quickstart",displayed_sidebar:"pushVideoSidebar",sidebar_position:3,image:"/assets/docs/previews/docs_video--quickstart.png"},l="Quickstart",o={id:"video/docs-video-quickstart",title:"Quickstart",description:"Everything you will need to get up and running in 5 mins or less!",source:"@site/docs/video/03-Quickstart-Push-Video.mdx",sourceDirName:"video",slug:"/video/quickstart",permalink:"/docs/video/quickstart",draft:!1,unlisted:!1,editUrl:"https://github.com/ethereum-push-notification-service/push-website/blob/main/docs/video/03-Quickstart-Push-Video.mdx",tags:[],version:"current",sidebarPosition:3,frontMatter:{id:"docs-video-quickstart",title:"Quickstart",hide_title:!1,slug:"./quickstart",displayed_sidebar:"pushVideoSidebar",sidebar_position:3,image:"/assets/docs/previews/docs_video--quickstart.png"},sidebar:"pushVideoSidebar",previous:{title:"Intro to Push Video",permalink:"/docs/video/"},next:{title:"Supported Wallet Standards",permalink:"/docs/video/supported-wallet-standards"}},c={},h=[{value:"Installation",id:"installation",level:3},{value:"Import libraries",id:"import-libraries",level:3},{value:"Initialize Video Instance",id:"initialize-video-instance",level:3},{value:"Initialize Media Stream",id:"initialize-media-stream",level:3},{value:"Request Video Call",id:"request-video-call",level:3},{value:"Incoming Video Call",id:"incoming-video-call",level:3},{value:"Accepting the Request",id:"accepting-the-request",level:3},{value:"Connect Call",id:"connect-call",level:3},{value:"Disconnect Call",id:"disconnect-call",level:3}];function u(e){const a={code:"code",h1:"h1",h3:"h3",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,s.a)(),...e.components},{Head:t}=a;return t||function(e,a){throw new Error("Expected "+(a?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Head",!0),(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(a.h1,{id:"quickstart",children:"Quickstart"}),"\n",(0,n.jsx)(a.p,{children:"Everything you will need to get up and running in 5 mins or less!"}),"\n",(0,n.jsx)(t,{children:(0,n.jsx)("title",{children:"Quickstart | Push Video | Push Documentation"})}),"\n","\n","\n",(0,n.jsx)(a.h3,{id:"installation",children:"Installation"}),"\n",(0,n.jsxs)(i.Z,{className:"codetabs",groupId:"code-examples",children:[(0,n.jsx)(r.Z,{value:"js",attributes:{className:"codetab js"},default:!0,children:(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-js",children:"// Install Libraries\nnpm install @pushprotocol/restapi@latest @pushprotocol/socket@latest ethers@^5.7\n"})})}),(0,n.jsx)(r.Z,{value:"react",attributes:{className:"codetab react"},children:(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-js",children:"// Install Libraries\nnpm install @pushprotocol/restapi@latest @pushprotocol/socket@latest ethers@^5.7\n"})})}),(0,n.jsx)(r.Z,{value:"reactnative",attributes:{className:"codetab reactnative"},children:(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-js",children:"// Install Libraries\nnpm install @pushprotocol/restapi@latest @pushprotocol/socket@latest ethers@^5.7\n"})})})]}),"\n",(0,n.jsx)(a.h3,{id:"import-libraries",children:"Import libraries"}),"\n",(0,n.jsxs)(i.Z,{className:"codetabs",groupId:"code-examples",children:[(0,n.jsx)(r.Z,{value:"js",attributes:{className:"codetab js"},default:!0,children:(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-js",children:'// Import restapi for function calls\n// Import socket for listening for real time messages\nimport { PushAPI, CONSTANTS } from "@pushprotocol/restapi";\nimport { createSocketConnection, EVENTS } from "@pushprotocol/socket";\n\n// Required to listen for incoming calls\nimport { VideoCallStatus } from "@pushprotocol/restapi";\nimport { ADDITIONAL_META_TYPE } from "@pushprotocol/restapi/src/lib/payloads/constants";\n\n// Ethers v5 or Viem, both are supported\nimport { ethers } from "ethers";\n'})})}),(0,n.jsx)(r.Z,{value:"react",attributes:{className:"codetab react"},children:(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-js",children:'// Import restapi for function calls\n// Import socket for listening for real time messages\nimport { PushAPI, CONSTANTS } from "@pushprotocol/restapi";\nimport { createSocketConnection, EVENTS } from "@pushprotocol/socket";\n\n// Required to listen for incoming calls\nimport { VideoCallStatus } from "@pushprotocol/restapi";\nimport { ADDITIONAL_META_TYPE } from "@pushprotocol/restapi/src/lib/payloads/constants";\n\n// Ethers v5 or Viem, both are supported\nimport { ethers } from "ethers";\n'})})}),(0,n.jsx)(r.Z,{value:"reactnative",attributes:{className:"codetab reactnative"},children:(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-js",children:'// Import restapi for function calls\n// Import socket for listening for real time messages\nimport { PushAPI, CONSTANTS } from "@pushprotocol/restapi";\nimport { createSocketConnection, EVENTS } from "@pushprotocol/socket";\n\n// Required to listen for incoming calls\nimport { VideoCallStatus } from "@pushprotocol/restapi";\nimport { ADDITIONAL_META_TYPE } from "@pushprotocol/restapi/src/lib/payloads/constants";\n\n// Ethers v5 or Viem, both are supported\nimport { ethers } from "ethers";\n'})})})]}),"\n",(0,n.jsx)(a.h3,{id:"initialize-video-instance",children:"Initialize Video Instance"}),"\n",(0,n.jsxs)(i.Z,{className:"codetabs",groupId:"code-examples",children:[(0,n.jsx)(r.Z,{value:"js",attributes:{className:"codetab js"},default:!0,children:(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-js",children:"// Creating a random signer from a wallet, ideally this is the wallet you will connect\nconst _signer = ethers.Wallet.createRandom();\n\n// Initialize wallet user, pass 'prod' instead of 'staging' for mainnet apps\nconst userAlice = await PushAPI.initialize(signer, { env: 'staging' });\n\n// get PGP private key\nconst encryptedPrivateKey = await userAlice.info().encryptedPrivateKey;\n\n// Initialize video object\nconst aliceVideoCall = new PushAPI.video.Video({\n  signer: _signer;\n  chainId: 1; // Pass 1 for Ethereum, 137 for Polygon, etc\n  pgpPrivateKey: encryptedPrivateKey; // Used to authenticate if users are connected\n  env?: 'staging'; // 'prod' or 'staging' environment\n  setData: (fn: (data: VideoCallData) => VideoCallData) => void; // Function to update the video call data, takes a function as an argument which receives the latest state of data as a param and should return the modified/new state of data\n});\n"})})}),(0,n.jsx)(r.Z,{value:"react",attributes:{className:"codetab react"},children:(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-js",children:"// Creating a random signer from a wallet, ideally this is the wallet you will connect\nconst _signer = ethers.Wallet.createRandom();\n\n// Initialize wallet user, pass 'prod' instead of 'staging' for mainnet apps\nconst userAlice = await PushAPI.initialize(signer, { env: 'staging' });\n\n// get PGP private key\nconst encryptedPrivateKey = await userAlice.info().encryptedPrivateKey;\n\n// Initialize video object\nconst aliceVideoCall = new PushAPI.video.Video({\n  signer: _signer;\n  chainId: 1; // Pass 1 for Ethereum, 137 for Polygon, etc\n  pgpPrivateKey: encryptedPrivateKey; // Used to authenticate if users are connected\n  env?: 'staging'; // 'prod' or 'staging' environment\n  setData: (fn: (data: VideoCallData) => VideoCallData) => void; // Function to update the video call data, takes a function as an argument which receives the latest state of data as a param and should return the modified/new state of data\n});\n"})})}),(0,n.jsx)(r.Z,{value:"reactnative",attributes:{className:"codetab reactnative"},children:(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-js",children:"// Creating a random signer from a wallet, ideally this is the wallet you will connect\nconst _signer = ethers.Wallet.createRandom();\n\n// Initialize wallet user, pass 'prod' instead of 'staging' for mainnet apps\nconst userAlice = await PushAPI.initialize(signer, { env: 'staging' });\n\n// get PGP private key\nconst encryptedPrivateKey = await userAlice.info().encryptedPrivateKey;\n\n// Initialize video object\nconst aliceVideoCall = new PushAPI.video.Video({\n  signer: _signer;\n  chainId: 1; // Pass 1 for Ethereum, 137 for Polygon, etc\n  pgpPrivateKey: encryptedPrivateKey; // Used to authenticate if users are connected\n  env: 'staging'; // 'prod' or 'staging' environment\n  setData: (fn: (data: VideoCallData) => VideoCallData) => void; // Function to update the video call data, takes a function as an argument which receives the latest state of data as a param and should return the modified/new state of data\n});\n"})})})]}),"\n",(0,n.jsx)(a.h3,{id:"initialize-media-stream",children:"Initialize Media Stream"}),"\n",(0,n.jsxs)(i.Z,{className:"codetabs",groupId:"code-examples",children:[(0,n.jsx)(r.Z,{value:"js",attributes:{className:"codetab js"},default:!0,children:(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-js",children:"// create or pass an existing media stream\nawait aliceVideoCall.create({\n  video: true; // to enable video on start\n  audio: true; // to enable audio on start\n});\n"})})}),(0,n.jsx)(r.Z,{value:"react",attributes:{className:"codetab react"},children:(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-js",children:"// create or pass an existing media stream\nawait aliceVideoCall.create({\n  video: true; // to enable video on start\n  audio: true; // to enable audio on start\n});\n"})})}),(0,n.jsx)(r.Z,{value:"reactnative",attributes:{className:"codetab reactnative"},children:(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-js",children:"// create or pass an existing media stream\nawait aliceVideoCall.create({\n  video: true; // to enable video on start\n  audio: true; // to enable audio on start\n});\n"})})})]}),"\n",(0,n.jsx)(a.h3,{id:"request-video-call",children:"Request Video Call"}),"\n",(0,n.jsxs)(i.Z,{className:"codetabs",groupId:"code-examples",children:[(0,n.jsx)(r.Z,{value:"js",attributes:{className:"codetab js"},default:!0,children:(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-js",children:"// request a call to a recipient wallet address\nawait aliceVideoCall.request({\n  senderAddress: signer.address;\n  recipientAddress: recipientWallet; // see supported wallet standards - https://push.org/docs/video/supported-wallet-standards\n  chatId: chatID; // pass in the chat id between sender and recipient, required, see - https://push.org/docs/chat to learn more\n});\n"})})}),(0,n.jsx)(r.Z,{value:"react",attributes:{className:"codetab react"},children:(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-js",children:"// request a call to a recipient wallet address\nawait aliceVideoCall.request({\n  senderAddress: signer.address;\n  recipientAddress: recipientWallet; // see supported wallet standards - https://push.org/docs/video/supported-wallet-standards\n  chatId: chatID; // pass in the chat id between sender and recipient, required, see - https://push.org/docs/chat to learn more\n});\n"})})}),(0,n.jsx)(r.Z,{value:"reactnative",attributes:{className:"codetab reactnative"},children:(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-js",children:"// request a call to a recipient wallet address\nawait aliceVideoCall.request({\n  senderAddress: signer.address;\n  recipientAddress: recipientWallet; // see supported wallet standards - https://push.org/docs/video/supported-wallet-standards\n  chatId: chatID; // pass in the chat id between sender and recipient, required, see - https://push.org/docs/chat to learn more\n});\n"})})})]}),"\n",(0,n.jsx)(a.h3,{id:"incoming-video-call",children:"Incoming Video Call"}),"\n",(0,n.jsxs)(i.Z,{className:"codetabs",groupId:"code-examples",children:[(0,n.jsx)(r.Z,{value:"js",attributes:{className:"codetab js"},default:!0,children:(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-jsx",children:"// Create Socket Connection\nconst pushSDKSocket = createSocketConnection({\n  user: signer.wallet,\n  socketType: 'chat',\n  socketOptions: { autoConnect: true, reconnectionAttempts: 3 },\n  env: 'staging',\n});\n\n// To listen to real time video calls\npushSDKSocket?.on(EVENTS.USER_FEEDS, (feedItem: any) => {\n  // we are listening for video call related notifications\n  // The event listner for the USER_FEEDS event\n  const { payload } = feedItem || {};\n\n  // we check if the additionalMeta property is present in payload.data\n  if (payload.hasOwnProperty('data') && payload['data'].hasOwnProperty('additionalMeta')) {\n    const additionalMeta = payload['data']['additionalMeta'];\n\n    // check for PUSH_VIDEO\n    if (additionalMeta.type === `${ADDITIONAL_META_TYPE.PUSH_VIDEO}+1`){\n      const videoCallMetaData = JSON.parse(additionalMeta.data);\n\n      // If the received status is INITIALIZED that means we have an incoming call\n      if (videoCallMetaData.status === VideoCallStatus.INITIALIZED) {\n        const {\n          // your address, ie the recipient address of the video call notification\n          recipientAddress,\n          // address of the other peer/user part of the video call, who sent you this notification\n          senderAddress,\n          // the unique identifier for every push chat, here, the one between the senderAddress and the recipientAddress\n          chatId,\n          // webRTC signal data received from the peer which sent this notification\n          signalData,\n          // current status of the video call, can be found from VideoCallStatus enum\n          status,\n        } = videoCallMetaData;\n\n        // Note - We'll need signalData while calling acceptRequest function\n        // You can save these properties in a state for furture use\n\n        /*\n        If you want you can also save these properties on the data state\n        we created while initializing the video object.\n        Later you can use it while calling acceptRequest()\n        signalData will be available via data.meta.initiator.signal\n        */\n        aliceVideoCall.setData((oldData) => {\n          return produce(oldData, (draft) => {\n            draft.local.address = recipientAddress;\n            draft.incoming[0].address = senderAddress;\n            draft.incoming[0].status = PushAPI.VideoCallStatus.RECEIVED;\n            draft.meta.chatId = chatId;\n            draft.meta.initiator.address = senderAddress;\n            draft.meta.initiator.signal = signalData;\n          });\n        });\n      }\n    }\n  }\n});\n"})})}),(0,n.jsx)(r.Z,{value:"react",attributes:{className:"codetab react"},children:(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-js",children:"// Create Socket Connection\nconst pushSDKSocket = createSocketConnection({\n  user: signer.wallet,\n  socketType: 'chat',\n  socketOptions: { autoConnect: true, reconnectionAttempts: 3 },\n  env: 'staging',\n});\n\n// To listen to real time video calls\npushSDKSocket?.on(EVENTS.USER_FEEDS, (feedItem: any) => {\n  // we are listening for video call related notifications\n  // The event listner for the USER_FEEDS event\n  const { payload } = feedItem || {};\n\n  // we check if the additionalMeta property is present in payload.data\n  if (payload.hasOwnProperty('data') && payload['data'].hasOwnProperty('additionalMeta')) {\n    const additionalMeta = payload['data']['additionalMeta'];\n\n    // check for PUSH_VIDEO\n    if (additionalMeta.type === `${ADDITIONAL_META_TYPE.PUSH_VIDEO}+1`){\n      const videoCallMetaData = JSON.parse(additionalMeta.data);\n\n      // If the received status is INITIALIZED that means we have an incoming call\n      if (videoCallMetaData.status === VideoCallStatus.INITIALIZED) {\n        const {\n          // your address, ie the recipient address of the video call notification\n          recipientAddress,\n          // address of the other peer/user part of the video call, who sent you this notification\n          senderAddress,\n          // the unique identifier for every push chat, here, the one between the senderAddress and the recipientAddress\n          chatId,\n          // webRTC signal data received from the peer which sent this notification\n          signalData,\n          // current status of the video call, can be found from VideoCallStatus enum\n          status,\n        } = videoCallMetaData;\n\n        // Note - We'll need signalData while calling acceptRequest function\n        // You can save these properties in a state for furture use\n\n        /*\n        If you want you can also save these properties on the data state\n        we created while initializing the video object.\n        Later you can use it while calling acceptRequest()\n        signalData will be available via data.meta.initiator.signal\n        */\n        aliceVideoCall.setData((oldData) => {\n          return produce(oldData, (draft) => {\n          draft.local.address = recipientAddress;\n          draft.incoming[0].address = senderAddress;\n          draft.incoming[0].status = PushAPI.VideoCallStatus.RECEIVED;\n          draft.meta.chatId = chatId;\n          draft.meta.initiator.address = senderAddress;\n          draft.meta.initiator.signal = signalData;\n          });\n        });\n      }\n    }\n  }\n});\n"})})}),(0,n.jsx)(r.Z,{value:"reactnative",attributes:{className:"codetab reactnative"},children:(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-js",children:"// Create Socket Connection\nconst pushSDKSocket = createSocketConnection({\n  user: signer.wallet,\n  socketType: 'chat',\n  socketOptions: { autoConnect: true, reconnectionAttempts: 3 },\n  env: 'staging',\n});\n\n// To listen to real time video calls\npushSDKSocket.on(EVENTS.USER_FEEDS, (feedItem: any) => {\n  // we are listening for video call related notifications\n  // The event listner for the USER_FEEDS event\n  const { payload } = feedItem || {};\n\n  // we check if the additionalMeta property is present in payload.data\n  if (payload.hasOwnProperty('data') && payload['data'].hasOwnProperty('additionalMeta')) {\n    const additionalMeta = payload['data']['additionalMeta'];\n\n    // check for PUSH_VIDEO\n    if (additionalMeta.type === `${ADDITIONAL_META_TYPE.PUSH_VIDEO}+1`){\n      const videoCallMetaData = JSON.parse(additionalMeta.data);\n\n      // If the received status is INITIALIZED that means we have an incoming call\n      if (videoCallMetaData.status === VideoCallStatus.INITIALIZED) {\n        const {\n          // your address, ie the recipient address of the video call notification\n          recipientAddress,\n          // address of the other peer/user part of the video call, who sent you this notification\n          senderAddress,\n          // the unique identifier for every push chat, here, the one between the senderAddress and the recipientAddress\n          chatId,\n          // webRTC signal data received from the peer which sent this notification\n          signalData,\n          // current status of the video call, can be found from VideoCallStatus enum\n          status,\n        } = videoCallMetaData;\n\n        // Note - We'll need signalData while calling acceptRequest function\n        // You can save these properties in a state for furture use\n\n        /*\n        If you want you can also save these properties on the data state\n        we created while initializing the video object.\n        Later you can use it while calling acceptRequest()\n        signalData will be available via data.meta.initiator.signal\n        */\n        aliceVideoCall.setData((oldData) => {\n          return produce(oldData, (draft) => {\n          draft.local.address = recipientAddress;\n          draft.incoming[0].address = senderAddress;\n          draft.incoming[0].status = PushAPI.VideoCallStatus.RECEIVED;\n          draft.meta.chatId = chatId;\n          draft.meta.initiator.address = senderAddress;\n          draft.meta.initiator.signal = signalData;\n          });\n        });\n      }\n    }\n  }\n});\n"})})})]}),"\n",(0,n.jsxs)(a.p,{children:["The ",(0,n.jsx)(a.code,{children:"additionalMeta"})," property has the following type:"]}),"\n",(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-jsx",children:"additionalMeta?: {\n  /**\n   * type = ADDITIONAL_META_TYPE+VERSION\n   * VERSION > 0\n   */\n  type: `${ADDITIONAL_META_TYPE}+${number}`;\n  data: string;\n  domain?: string;\n};\n"})}),"\n",(0,n.jsxs)(a.p,{children:["When you parse the ",(0,n.jsx)(a.code,{children:"data"})," property from the ",(0,n.jsx)(a.code,{children:"additionalMeta"})," object, you'll receive the ",(0,n.jsx)(a.code,{children:"videoCallMetaData"}),", which has the following type:"]}),"\n",(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-jsx",children:"interface VideoCallMetaDataType {\n  recipientAddress: string;\n  senderAddress: string;\n  chatId: string;\n  signalData?: any;\n  status: VideoCallStatus;\n}\n"})}),"\n",(0,n.jsxs)(a.table,{children:[(0,n.jsx)(a.thead,{children:(0,n.jsxs)(a.tr,{children:[(0,n.jsx)(a.th,{children:"Property"}),(0,n.jsx)(a.th,{children:"Description"})]})}),(0,n.jsxs)(a.tbody,{children:[(0,n.jsxs)(a.tr,{children:[(0,n.jsx)(a.td,{children:(0,n.jsx)(a.code,{children:"recipientAddress"})}),(0,n.jsx)(a.td,{children:"Wallet address of remote peer/user ie the address which you want to call"})]}),(0,n.jsxs)(a.tr,{children:[(0,n.jsx)(a.td,{children:(0,n.jsx)(a.code,{children:"senderAddress"})}),(0,n.jsx)(a.td,{children:"Wallet address of the local peer/user"})]}),(0,n.jsxs)(a.tr,{children:[(0,n.jsx)(a.td,{children:(0,n.jsx)(a.code,{children:"chatId"})}),(0,n.jsx)(a.td,{children:"Unique identifier for every push chat, here, the one between the senderAddress and the recipientAddress"})]}),(0,n.jsxs)(a.tr,{children:[(0,n.jsx)(a.td,{children:(0,n.jsx)(a.code,{children:"signalingData"})}),(0,n.jsx)(a.td,{children:"WebRTC signal data received from the peer which sent this notification"})]}),(0,n.jsxs)(a.tr,{children:[(0,n.jsx)(a.td,{children:(0,n.jsx)(a.code,{children:"status"})}),(0,n.jsx)(a.td,{children:"Current status of the video call, can be found from VideoCallStatus enum"})]})]})]}),"\n",(0,n.jsx)(a.h3,{id:"accepting-the-request",children:"Accepting the Request"}),"\n",(0,n.jsx)(a.p,{children:"After receiving a request for a video call, you can show a sort of incoming call UI. Now it's time to accept the request for a video call on the receiver's end. For this, we'll need the signalData we received from the event handler of the USER_FEEDS event above."}),"\n",(0,n.jsxs)(i.Z,{className:"codetabs",groupId:"code-examples",children:[(0,n.jsx)(r.Z,{value:"js",attributes:{className:"codetab js"},default:!0,children:(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-jsx",children:"await aliceVideoCall.acceptRequest({\n  signalData: any;\n  senderAddress: string;\n  recipientAddress: string;\n  chatId: string;\n  onReceiveMessage?: (message: string) => void;\n  retry?: boolean;\n});\n\n// Note: If you saved the properties from the additionalMeta received in the sockets\n// You can call acceptRequest() like below:\nawait aliceVideoCall.acceptRequest({\n  signalData: data.meta.initiator.signal;\n  senderAddress: data.local.address;\n  recipientAddress: data.incoming[0].address;\n  chatId: data.meta.chatId;\n});\n"})})}),(0,n.jsx)(r.Z,{value:"react",attributes:{className:"codetab react"},children:(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-jsx",children:"await aliceVideoCall.acceptRequest({\n  signalData: any;\n  senderAddress: string;\n  recipientAddress: string;\n  chatId: string;\n  onReceiveMessage?: (message: string) => void;\n  retry?: boolean;\n});\n\n// Note: If you saved the properties from the additionalMeta received in the sockets\n// You can call acceptRequest() like below:\nawait aliceVideoCall.acceptRequest({\n  signalData: data.meta.initiator.signal;\n  senderAddress: data.local.address;\n  recipientAddress: data.incoming[0].address;\n  chatId: data.meta.chatId;\n});\n"})})}),(0,n.jsx)(r.Z,{value:"reactnative",attributes:{className:"codetab reactnative"},children:(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-jsx",children:"await aliceVideoCall.acceptRequest({\n  signalData: any;\n  senderAddress: string;\n  recipientAddress: string;\n  chatId: string;\n  onReceiveMessage?: (message: string) => void;\n  retry?: boolean;\n});\n\n// Note: If you saved the properties from the additionalMeta received in the sockets\n// You can call acceptRequest() like below:\nawait aliceVideoCall.acceptRequest({\n  signalData: data.meta.initiator.signal;\n  senderAddress: data.local.address;\n  recipientAddress: data.incoming[0].address;\n  chatId: data.meta.chatId;\n});\n"})})})]}),"\n",(0,n.jsxs)(a.table,{children:[(0,n.jsx)(a.thead,{children:(0,n.jsxs)(a.tr,{children:[(0,n.jsx)(a.th,{children:"Property"}),(0,n.jsx)(a.th,{children:"Description"})]})}),(0,n.jsxs)(a.tbody,{children:[(0,n.jsxs)(a.tr,{children:[(0,n.jsx)(a.td,{children:"signalData"}),(0,n.jsx)(a.td,{children:"Signal data received from the initiator peer via push notification upon request() call"})]}),(0,n.jsxs)(a.tr,{children:[(0,n.jsx)(a.td,{children:"senderAddress"}),(0,n.jsx)(a.td,{children:"Wallet address of the local peer/user"})]}),(0,n.jsxs)(a.tr,{children:[(0,n.jsx)(a.td,{children:"recipientAddress"}),(0,n.jsx)(a.td,{children:"Wallet address of remote peer/user ie the address which you want to call"})]}),(0,n.jsxs)(a.tr,{children:[(0,n.jsx)(a.td,{children:"chatId"}),(0,n.jsx)(a.td,{children:"Unique identifier for every push chat, here, the one between the senderAddress and the recipientAddress"})]}),(0,n.jsxs)(a.tr,{children:[(0,n.jsx)(a.td,{children:"onReceiveMessage"}),(0,n.jsx)(a.td,{children:"Function which will be called when the sender receives a message via webRTC data channel"})]}),(0,n.jsxs)(a.tr,{children:[(0,n.jsx)(a.td,{children:"retry"}),(0,n.jsx)(a.td,{children:"If we are retrying the call, only for internal use"})]})]})]}),"\n",(0,n.jsx)(a.h3,{id:"connect-call",children:"Connect Call"}),"\n",(0,n.jsxs)(a.p,{children:["Now, to finally connect a video call on the initiator's end, we need to listen for the ",(0,n.jsx)(a.code,{children:"USER_FEEDS"})," event from ",(0,n.jsx)(a.code,{children:"@pushprotocol/socket"})," and use the following code inside of the event listener:"]}),"\n",(0,n.jsxs)(i.Z,{className:"codetabs",groupId:"code-examples",children:[(0,n.jsx)(r.Z,{value:"js",attributes:{className:"codetab js"},default:!0,children:(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-jsx",children:"pushSDKSocket?.on(EVENTS.USER_FEEDS, (feedItem: any) => {\n  // The event listner for the USER_FEEDS event\n  const { payload } = feedItem || {};\n  //We check if the additionalMeta property is present in payload.data\n  if (payload.hasOwnProperty('data') && payload['data'].hasOwnProperty('additionalMeta')) {\n\n    const additionalMeta = payload['data']['additionalMeta'];\n\n    // check for PUSH_VIDEO\n    if (additionalMeta.type === `${ADDITIONAL_META_TYPE.PUSH_VIDEO}+1`){\n      const videoCallMetaData = JSON.parse(additionalMeta.data);\n\n      // If the received status is RECEIVED that means we can connect the video call\n      if (videoCallMetaData.status === VideoCallStatus.RECEIVED) {\n        const {\n          signalData,\n        } = videoCallMetaData;\n\n        // connecting the call using received signalData\n        aliceVideoCall.connect({\n          signalData,\n        })\n      }\n    }\n  }\n});\n"})})}),(0,n.jsx)(r.Z,{value:"react",attributes:{className:"codetab react"},children:(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-jsx",children:"pushSDKSocket?.on(EVENTS.USER_FEEDS, (feedItem: any) => {\n  // The event listner for the USER_FEEDS event\n  const { payload } = feedItem || {};\n  //We check if the additionalMeta property is present in payload.data\n  if (payload.hasOwnProperty('data') && payload['data'].hasOwnProperty('additionalMeta')) {\n\n    const additionalMeta = payload['data']['additionalMeta'];\n\n    // check for PUSH_VIDEO\n    if (additionalMeta.type === `${ADDITIONAL_META_TYPE.PUSH_VIDEO}+1`){\n      const videoCallMetaData = JSON.parse(additionalMeta.data);\n\n      // If the received status is RECEIVED that means we can connect the video call\n      if (videoCallMetaData.status === VideoCallStatus.RECEIVED) {\n        const {\n          signalData,\n        } = videoCallMetaData;\n\n        // connecting the call using received signalData\n        aliceVideoCall.connect({\n          signalData,\n        })\n      }\n    }\n  }\n});\n"})})}),(0,n.jsx)(r.Z,{value:"reactnative",attributes:{className:"codetab reactnative"},children:(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-jsx",children:"pushSDKSocket?.on(EVENTS.USER_FEEDS, (feedItem: any) => {\n  // The event listner for the USER_FEEDS event\n  const { payload } = feedItem || {};\n  //We check if the additionalMeta property is present in payload.data\n  if (payload.hasOwnProperty('data') && payload['data'].hasOwnProperty('additionalMeta')) {\n\n    const additionalMeta = payload['data']['additionalMeta'];\n\n    // check for PUSH_VIDEO\n    if (additionalMeta.type === `${ADDITIONAL_META_TYPE.PUSH_VIDEO}+1`){\n      const videoCallMetaData = JSON.parse(additionalMeta.data);\n\n      // If the received status is RECEIVED that means we can connect the video call\n      if (videoCallMetaData.status === VideoCallStatus.RECEIVED) {\n        const {\n          signalData,\n        } = videoCallMetaData;\n\n        // connecting the call using received signalData\n        aliceVideoCall.connect({\n          signalData,\n        })\n      }\n    }\n  }\n});\n"})})})]}),"\n",(0,n.jsxs)(a.table,{children:[(0,n.jsx)(a.thead,{children:(0,n.jsxs)(a.tr,{children:[(0,n.jsx)(a.th,{children:"Property"}),(0,n.jsx)(a.th,{children:"Description"})]})}),(0,n.jsx)(a.tbody,{children:(0,n.jsxs)(a.tr,{children:[(0,n.jsx)(a.td,{children:(0,n.jsx)(a.code,{children:"signalData"})}),(0,n.jsx)(a.td,{children:"Signal data received from the receiver peer via push notification upon acceptRequest() call"})]})})]}),"\n",(0,n.jsx)(a.h3,{id:"disconnect-call",children:"Disconnect Call"}),"\n",(0,n.jsxs)(a.p,{children:["To disconnect a call, we use the ",(0,n.jsx)(a.code,{children:"disconnect()"})," method on the videoObject (aliceVideoCall)."]}),"\n",(0,n.jsxs)(i.Z,{className:"codetabs",groupId:"code-examples",children:[(0,n.jsx)(r.Z,{value:"js",attributes:{className:"codetab js"},default:!0,children:(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-jsx",children:"// to disconnect the call\naliceVideoCall.disconnect();\n\npushSDKSocket?.on(EVENTS.USER_FEEDS, (feedItem: any) => {\n  // The event listner for the USER_FEEDS event\n\n  const { payload } = feedItem || {};\n  // we check if the additionalMeta property is present in payload.data\n  if (payload.hasOwnProperty('data') && payload['data'].hasOwnProperty('additionalMeta')) {\n    // parsing additionalMeta\n    const additionalMeta = payload['data']['additionalMeta'];\n\n    // check for PUSH_VIDEO\n    if (additionalMeta.type === `${ADDITIONAL_META_TYPE.PUSH_VIDEO}+1`){\n      const videoCallMetaData = JSON.parse(additionalMeta.data);\n\n      // If the received status is DISCONNECTED that means the call has ended\n      if (videoCallMetaData.status === VideoCallStatus.DISCONNECTED) {\n          // here you can do a window reload or just clear out the video state\n      }\n    }\n  }\n});\n"})})}),(0,n.jsx)(r.Z,{value:"react",attributes:{className:"codetab react"},children:(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-jsx",children:"// to disconnect the call\naliceVideoCall.disconnect();\n\npushSDKSocket?.on(EVENTS.USER_FEEDS, (feedItem: any) => {\n  // The event listner for the USER_FEEDS event\n\n  const { payload } = feedItem || {};\n  // we check if the additionalMeta property is present in payload.data\n  if (payload.hasOwnProperty('data') && payload['data'].hasOwnProperty('additionalMeta')) {\n    // parsing additionalMeta\n    const additionalMeta = payload['data']['additionalMeta'];\n\n    // check for PUSH_VIDEO\n    if (additionalMeta.type === `${ADDITIONAL_META_TYPE.PUSH_VIDEO}+1`){\n      const videoCallMetaData = JSON.parse(additionalMeta.data);\n\n      // If the received status is DISCONNECTED that means the call has ended\n      if (videoCallMetaData.status === VideoCallStatus.DISCONNECTED) {\n          // here you can do a window reload or just clear out the video state\n      }\n    }\n  }\n});\n"})})}),(0,n.jsx)(r.Z,{value:"reactnative",attributes:{className:"codetab reactnative"},children:(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-jsx",children:"// to disconnect the call\naliceVideoCall.disconnect();\n\npushSDKSocket?.on(EVENTS.USER_FEEDS, (feedItem: any) => {\n  // The event listner for the USER_FEEDS event\n\n  const { payload } = feedItem || {};\n  // we check if the additionalMeta property is present in payload.data\n  if (payload.hasOwnProperty('data') && payload['data'].hasOwnProperty('additionalMeta')) {\n    // parsing additionalMeta\n    const additionalMeta = payload['data']['additionalMeta'];\n\n    // check for PUSH_VIDEO\n    if (additionalMeta.type === `${ADDITIONAL_META_TYPE.PUSH_VIDEO}+1`){\n      const videoCallMetaData = JSON.parse(additionalMeta.data);\n\n      // If the received status is DISCONNECTED that means the call has ended\n      if (videoCallMetaData.status === VideoCallStatus.DISCONNECTED) {\n          // here you can do a window reload or just clear out the video state\n      }\n    }\n  }\n});\n"})})})]})]})}function p(e={}){const{wrapper:a}={...(0,s.a)(),...e.components};return a?(0,n.jsx)(a,{...e,children:(0,n.jsx)(u,{...e})}):u(e)}},85162:(e,a,t)=>{t.d(a,{Z:()=>r});t(67294);var n=t(86010);const s={tabItem:"tabItem_Ymn6"};var i=t(85893);function r(e){let{children:a,hidden:t,className:r}=e;return(0,i.jsx)("div",{role:"tabpanel",className:(0,n.default)(s.tabItem,r),hidden:t,children:a})}},74866:(e,a,t)=>{t.d(a,{Z:()=>b});var n=t(67294),s=t(86010),i=t(12466),r=t(16550),d=t(20469),l=t(91980),o=t(67392),c=t(50012);function h(e){var a,t;return null!==(a=null===(t=n.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,n.isValidElement)(e)&&function(e){const{props:a}=e;return!!a&&"object"==typeof a&&"value"in a}(e))return e;throw new Error("Docusaurus error: Bad <Tabs> child <"+("string"==typeof e.type?e.type:e.type.name)+'>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.')})))||void 0===t?void 0:t.filter(Boolean))&&void 0!==a?a:[]}function u(e){const{values:a,children:t}=e;return(0,n.useMemo)((()=>{const e=null!=a?a:function(e){return h(e).map((e=>{let{props:{value:a,label:t,attributes:n,default:s}}=e;return{value:a,label:t,attributes:n,default:s}}))}(t);return function(e){const a=(0,o.l)(e,((e,a)=>e.value===a.value));if(a.length>0)throw new Error('Docusaurus error: Duplicate values "'+a.map((e=>e.value)).join(", ")+'" found in <Tabs>. Every value needs to be unique.')}(e),e}),[a,t])}function p(e){let{value:a,tabValues:t}=e;return t.some((e=>e.value===a))}function f(e){let{queryString:a=!1,groupId:t}=e;const s=(0,r.k6)(),i=function(e){let{queryString:a=!1,groupId:t}=e;if("string"==typeof a)return a;if(!1===a)return null;if(!0===a&&!t)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return null!=t?t:null}({queryString:a,groupId:t});return[(0,l._X)(i),(0,n.useCallback)((e=>{if(!i)return;const a=new URLSearchParams(s.location.search);a.set(i,e),s.replace({...s.location,search:a.toString()})}),[i,s])]}function m(e){const{defaultValue:a,queryString:t=!1,groupId:s}=e,i=u(e),[r,l]=(0,n.useState)((()=>function(e){var a;let{defaultValue:t,tabValues:n}=e;if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(t){if(!p({value:t,tabValues:n}))throw new Error('Docusaurus error: The <Tabs> has a defaultValue "'+t+'" but none of its children has the corresponding value. Available values are: '+n.map((e=>e.value)).join(", ")+". If you intend to show no default tab, use defaultValue={null} instead.");return t}const s=null!==(a=n.find((e=>e.default)))&&void 0!==a?a:n[0];if(!s)throw new Error("Unexpected error: 0 tabValues");return s.value}({defaultValue:a,tabValues:i}))),[o,h]=f({queryString:t,groupId:s}),[m,v]=function(e){let{groupId:a}=e;const t=function(e){return e?"docusaurus.tab."+e:null}(a),[s,i]=(0,c.Nk)(t);return[s,(0,n.useCallback)((e=>{t&&i.set(e)}),[t,i])]}({groupId:s}),g=(()=>{const e=null!=o?o:m;return p({value:e,tabValues:i})?e:null})();(0,d.Z)((()=>{g&&l(g)}),[g]);return{selectedValue:r,selectValue:(0,n.useCallback)((e=>{if(!p({value:e,tabValues:i}))throw new Error("Can't select invalid tab value="+e);l(e),h(e),v(e)}),[h,v,i]),tabValues:i}}var v=t(72389);const g={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var j=t(85893);function x(e){let{className:a,block:t,selectedValue:n,selectValue:r,tabValues:d}=e;const l=[],{blockElementScrollPositionUntilNextRender:o}=(0,i.o5)(),c=e=>{const a=e.currentTarget,t=l.indexOf(a),s=d[t].value;s!==n&&(o(a),r(s))},h=e=>{var a;let t=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{var n;const a=l.indexOf(e.currentTarget)+1;t=null!==(n=l[a])&&void 0!==n?n:l[0];break}case"ArrowLeft":{var s;const a=l.indexOf(e.currentTarget)-1;t=null!==(s=l[a])&&void 0!==s?s:l[l.length-1];break}}null===(a=t)||void 0===a||a.focus()};return(0,j.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,s.default)("tabs",{"tabs--block":t},a),children:d.map((e=>{let{value:a,label:t,attributes:i}=e;return(0,j.jsx)("li",{role:"tab",tabIndex:n===a?0:-1,"aria-selected":n===a,ref:e=>l.push(e),onKeyDown:h,onClick:c,...i,className:(0,s.default)("tabs__item",g.tabItem,null==i?void 0:i.className,{"tabs__item--active":n===a}),children:null!=t?t:a},a)}))})}function y(e){let{lazy:a,children:t,selectedValue:s}=e;const i=(Array.isArray(t)?t:[t]).filter(Boolean);if(a){const e=i.find((e=>e.props.value===s));return e?(0,n.cloneElement)(e,{className:"margin-top--md"}):null}return(0,j.jsx)("div",{className:"margin-top--md",children:i.map(((e,a)=>(0,n.cloneElement)(e,{key:a,hidden:e.props.value!==s})))})}function I(e){const a=m(e);return(0,j.jsxs)("div",{className:(0,s.default)("tabs-container",g.tabList),children:[(0,j.jsx)(x,{...e,...a}),(0,j.jsx)(y,{...e,...a})]})}function b(e){const a=(0,v.Z)();return(0,j.jsx)(I,{...e,children:h(e.children)},String(a))}},11151:(e,a,t)=>{t.d(a,{Z:()=>d,a:()=>r});var n=t(67294);const s={},i=n.createContext(s);function r(e){const a=n.useContext(i);return n.useMemo((function(){return"function"==typeof e?e(a):{...a,...e}}),[a,e])}function d(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),n.createElement(i.Provider,{value:a},e.children)}}}]);